% !TeX root=main.tex

\section{Analytical Model Derivation}
\label{sec:analytical_model}

In this section, we will present a derivation of the analytical model of an SDN and NFV enabled MCC datacenter. The model is capable of analysing the end-to-end service performance of multiple coexisting service chains, each of which will can have different numbers of VNFs. The impact of the centralised SDN controller on the end-to-end performance provisioning is also studied in the developed model. With the aim of increasing the readability of the model derivation, we first consider the case of a single service scenario consisting of only two VNFs, then this simplified model will be extended to the realistic scenario of multiple NFV service chains with varying length.

\subsubsection{Simple NFV Deployment Scenario}
For the SDN and NFV enabled fat-tree network established in Section \ref{sec:preliminaries}, the end-to-end latency of a service is dependent on the probability that a packet will visit a certain layer of switches. Additionally, applying the widely used Equal-Cost Multi-Path (ECMP) \cite{ChiesaKS17} routing protocol to this network and the expected waiting time is the same for every component on each layer. In the case of just two VNFs packets will only need to cross the network one time and the latency depends on the highest level the packets must traverse to reach the other VNF. The end-to-end latency from one VNF to another can then be written as,

\begin{equation}
    \label{eq:mean_latency}
    L_t = w_v + \sum_{i=0}^3 L_i(\lambda_i, \rho_i) \cdot p_i
\end{equation}

\noindent where ``$i=0$'' represents the virtual switch layer, and ``$i=1,2,3$'' denotes the edge, aggregation and core layers respectively. $L_i(\lambda_i, \rho_i,)$ denotes the end to end latency when the packets need to travel to the $i$th layer network switches and $w_v$ gives the expected waiting time at the VNF. Similarly $p_i$ represent the probability that a packet must use the $i$th layer of switches.

$L_i(\lambda_i, \rho_i)$ is the sum of the waiting time from the VNFs to the $i$th layer switch and back, and can be calculated by,
\begin{equation}
    \label{eq:latency_path}
    \begin{split}
        L_i(\lambda_i, \rho_i) = w_i + 2 \sum_{j=0}^{i-1} w_j
    \end{split}
\end{equation}

\noindent where $w_j$ is the processing time at the $j$th layer of switches. For the virtual switches, the waiting time $w_0$ includes the time waiting at the switch and also for a reply from the SDN controller: $w_0 = p_c (w_c + w_{vs}) + w_{vs}$, where $p_c$ is the probability that a packet will be forwarded to the SDN controller and $w_{vs}$ is the waiting time at the virtual switch.

We must now calculate the remaining waiting times and probabilities. If the source and destination VNFs share the same virtual switch, then packets between two VNF will not visit a higher layer switch. Let the probability of a packet only visiting a virtual switch be $p_0$ which can be calculated by

\begin{equation}
    \label{eq:p_vm}
    p_{0} = \frac{k_{v} - 1}{n_v - 1}
\end{equation}
\noindent where $n_v = k^3/4$ denotes the total number of VNFs in the datacenter.

In the fat-tree topology, the higher layer switches connect more VNFs. The probability of a VNF sending packets via an edge switch is the proportion of destination VNFs under the edge switch, excluding destinations that can be visited via a shorter path i.e. via a shared virtual switch. Therefore, $p_1$ can be derived with the following equation,

\begin{equation}
    \label{eq:p_edge}
    p_{1} = \frac{\left(\frac{k}{2}-1\right) \cdot k_v}{n_v - 1}
\end{equation}

Using the method the probability of visiting the aggregate and core layers can be calculated with,
\begin{align}
    \label{eq:p_agg_core}
     & p_{2}=\frac { \left(\frac{k}{2}-1\right)\cdot k \cdot k_v }{2 \cdot (n_v-1) } \\ \nonumber \\
     & p_{3} = \frac{n_v - (\frac{k}{2}^2 \cdot k_{v}}{n_v - 1}
\end{align}

At the virtual switch, the SDN controller will only be consulted if the destination VNF is located in another physical server, and the destination is not contained in the routing table of the virtual switch in that server. The probability that the packets will be sent to SDN controller for routing information can be calculated by,
\begin{equation}
    \label{eq:p_sdn}
    p_{c} = (1 - p_{0}) \cdot p_m
\end{equation}

After obtaining the probability that a packet will be processed at the different layers of switches and SDN controller. The following subsection derives the waiting time at each component of the routing path. According to \cite{Kleinrock75}, the waiting time for a M/M/1 queue is obtained by

\begin{equation}
    \label{eq:p_latency}
    w(\mu, \lambda) = \frac{1}{\mu - \lambda}
\end{equation}

where $\mu$ is the service rate and $\lambda$ is the arrival rate for an M/M/1 queue. In the following, we aim to calculate the arrive rate at the VNFs, SDN controller and different layers of switches. As the destinations are evenly distributed over the VNFs, each VNF will receive an equal proportion of packets from other VNF. Hence each VNF receives traffic at rate $\lambda$. Virtual switches realise the communications among VMs, so virtual switches can receive packets from three sources: 1) packets generated by VNFs on the same server as the virtual switch 2) traffic generated by the VNFs in the other servers and 3) packets sent back from the SDN controller. Hence the arrival rate at the virtual switch can be calculated by,
\begin{equation}
    \label{eq:arr_srv}
    \lambda_0 = \lambda \cdot \left(1+\frac{n_v - k_v}{n_v - 1} + p_c \right)
\end{equation}

The arrival rate for the edge switches can be calculated similar to the virtual switch. It should be noticed that packets that are intended for destinations on the same server do not need to visit the edge switch. The arrival rate at the edge switch can hence be calculated by,
\begin{equation}
    \label{eq:arr_edge}
    \lambda_1 = \frac{\lambda \cdot k \cdot k_v}{2(n - 1)}\left(2n - k_v \left( 1 + \frac{k}{2} \right)\right)
\end{equation}

Under the ECMP protocol, traffic will be balanced among aggregate switches in a pod and VNFs sharing the same virtual or edge switches will not use the aggregation switches. The arrival rate at each aggregate switch can then be computed by,
\begin{equation}
    \label{eq:arr_agg}
    \lambda_2 = \frac{2 \lambda \cdot k \cdot k_v}{n_v - 1} \left(2n_v - k_v \frac{k}{2} (1 - \frac{k}{2}) \right)
\end{equation}

As all VNFs are connected by the core switches, the arrival rate at each core switch is the portion of traffic that cannot be reached by any other switch. Using ECMP, the traffic leaving the aggregation layer will be evenly split amongst the different core switches. Therefore the arrival rate at the core switch can be calculated with,
\begin{equation}
    \label{eq:arr_core}
    \lambda_3 =\frac{\lambda_f \cdot p_3 \cdot n_v}{(k/2)^2}
\end{equation}

Finally, let us calculate the traffic rate for the SDN controller. It can be observed that the packets visiting the SDN controller do not change the arrival rate of higher level switches, e.g. edge or aggregation switches; and a portion of the traffic in the virtual switch will be sent to SDN controller for routing decision making. Given the number of VNFs $n_v = (k^3 / 4) \cdot k_v$ the arrival rate at the SDN controller is computed by,
\begin{equation}
    \label{eq:arr_sdn}
    \lambda_c = \lambda \cdot n_v \cdot p_c
\end{equation}

By substituting the arrival rates (Eqs. \ref{eq:arr_srv} to \ref{eq:arr_core}) and service rates of each network component into M/M/1 latency equation, we can obtain the average waiting time at each VNF, and at the different layers of switches. Substituting the probabilities of the different paths and the mean waiting time into Eq. (\ref{eq:mean_latency}), we obtain the end to end latency for the simple VNF deployment scenario.

\subsubsection{Realistic NFV Deployment Scenario} 
\label{sec:realistic}

Although there are several papers investigating the performance of NFV, existing research only considers the case of a single NFV service, paying little attention to the case of multiple coexisting services. Given the fact that datacenter infrastructure is always used to simultaneously support multiple services, it is necessary to investigate the performance of an SDN and NFV enabled datacenter network with different numbers of services. In this subsection, we will extend the simplified NFV deployment scenario into the case of multiple VNFs of varying lengths.

Let $N_s$ denote the number of NFV services deployed in the datacenter and $K_i$ represent the length of the $i$th service. As each VNF except the last one in a service chain will forward on the packets it receives, packets will persist longer in the network, increasing the effective arrival rate at each network element. From the perspective of the network, the network infrastructure receives packets from $K_i-1$ VNFs for the $i$th service and hence the effective network traffic rate that $i$th service chain generates can be written as $\lambda_{i}^{e} = \lambda_{i} \cdot (K_i - 1)$, where $\lambda_{i}$ is the traffic rate of the $i$th service and the $\lambda_{i}^e$ is the effective traffic rate that the network infrastructure receives. In this analytical model, different network service can have different length  service chains. As NFV services are independent with each other, let $p_{i,s}$ denote the probability that a packet is from the $i$th service. The effective network traffic the network infrastructure receives can then be obtained by
\begin{equation}
    \label{eq:effective_arrival}
    \lambda^e =\sum_{i=1}^{N_s} \lambda_{i} \cdot K_{i-1} \cdot p_{i,s}
\end{equation}

Similar to the simple NFV deployment case, the expected end-to-end latency is the sum time spent taking each path. By substituting the effective traffic rate in Eq. (\ref{eq:effective_arrival}) into Eqs. (\ref{eq:arr_srv}-\ref{eq:arr_sdn}), we can calculate the effective network traffic in each network layer. Given the service rates $\mu_v$, $\mu_e$, $\mu_a$, and $\mu_s$, the latency, $w_j$ can then be obtained for each network layer. After calculating the probability that a packet visits a certain network layer, the end-to-end latency can be calculated by Eq (\ref{eq:mean_latency}). For convenience, pseudocode for the entire process is given in Algorithm \ref{alg:avg_latency_final}.

\begin{algorithm}

    \caption{Calculation of Average Latency of SND and NFV-enabled MCC Datacenter Networks}
    \label{alg:avg_latency_final}

    \begin{algorithmic}[1]
        %\renewcommand{\algorithmicrequire}{\textbf{Input:}}
        %\REQUIRE $\alpha$, $k$, $k_{vm}$, $\mu_{sw/vnf/sdn}$, $p_{miss\_route}$, $p(service_i)$ 
        \STATE Calculate the effective network traffic: $\lambda_f^e$ \hfill(\textit{Eq. (\ref{eq:effective_arrival})})
        \STATE Calculate the traffic rates: $\lambda_i$ \hfill(\textit{Eqs. (\ref{eq:p_vm}-\ref{eq:p_sdn})})
        \STATE Calculate the probability: $p_i$ \hfill(\textit{Eqs. (\ref{eq:arr_srv}-\ref{eq:arr_sdn})})
        \STATE Calculate the waiting times: \hfill(\textit{Eq. (\ref{eq:p_latency})})
        \STATE Calculate the latency for the $i$th path: $L_i$ \hfill (\textit{Eq. (\ref{eq:latency_path})})
        \STATE Calculate the latency for the end to end transmission: $L_t$ \hfill (\textit{Eq. (\ref{eq:mean_latency})})
    \end{algorithmic}
\end{algorithm}