% !TeX root=main.tex

\section{Analytical Model Derivation}
\label{sec:analytical_model}

In this section, we will present the methodology and approaches to derive the analytical model of SND and NFV enabled MCC datacenter. The model to be designed will be capable of analysing the end-to-end service performance with the coexistence of multiple NFVs, each of which will have different number of VNFs with respect to different MCC services. The impact of the centralised control of SDN controller on the end-to-end performance provisioning is also studied in the developed model. With the aim of increasing the readability of model derivation, we firstly consider the case of single NFV deployment scenario in the analytical derivation, then the simplified version will be extended to the scenario of multiple NFV service chains. 

\subsubsection{Single NFV deployment Case}

According to the widely used Equal-Cost Multi-path Routing (ECMR) \cite{Chiesa} in datacenter network, the end-to-end latency is dependant on the probability that a packet will visit a certain layer of switches and the waiting times in each layer. The end-to-end latency can be written as, 
\begin{equation} 
\label{eq:mean_latency}
\begin{split}
{ L }_{ t }=\prod _{ i=0 }^{ 3 }{ { L }_{ i }({ \lambda  }_{ i },\mu _{ i }){ p }_{ i } } 
\end{split}
\end{equation}

\noindent where ``$i=0$'' represents the virtual switch layer, and ``$i=1,2,3$'' denotes the edge, aggregation and core layers respectively. ${ L }_{ i }({ \lambda  }_{ i },\mu _{ i })$ denotes the end to end latency when the packets need to travel to the $i$th layer network switches. Similarly $p_i$ represent the probability that a packet could reach the $i$th layer switches. ${ L }_{ i }({ \lambda  }_{ i },\mu _{ i })$ is the sum of the latency the packets experience from VNF nodes to the $i$th layer switches, which can be calculated by, 
\begin{equation}
\label{eq:latency:path}
\begin{split}
{ L }_{ i }({ \lambda  }_{ i },\mu _{ i })={ w }_{ f }+\sum _{ j=0 }^{ i }{ { w }_{ j } } 
\end{split}
\end{equation}
\noindent where $w_{f}$ is the processing latency within a VFN. $w_j$ is the latency at the $j$th layer of the switches. For the virtual switches, the latency, $w_0$, has two parts, the latency at the virtual switch and latency at the SDN controller. Therefore, $w_0=p_cw_c + (1-p_c)w_v$, where $p_c$ is the probability that a packet will be forward to SDN controller for the routing decision making. If the source and destination VNFs share the same virtual switch, the packets between two VNF will not visit a higher layer switch. Let the probability of a packet only visiting a virtual switch, $p_0$, denote is the probability that the source and destination VNFs are under the same virtual switch. $p_0$ can be calculated by 
\begin{equation}
\label{eq:p_vm}
p_{0} = \frac{k_{f} - 1}{n_v - 1}
\end{equation}
\noindent where $n_v$ denotes the total number of VMs in the datacenter.

Based on the topology of fat-tree structure, the higher layer a packet can reach means that the more destinations this packet could visit. If the switches that a packet visits is at edge layer, then the probability that the destination VNF is under the same edge switch can be calculated by excluding destinations that could be visited via a shorter path. In this case, the short path would be virtual switches. Therefore, $p_1$ can be derived from the following equation, 
\begin{equation}
\label{eq:p_edge}
p_{1} = \frac{(k/2-1) \cdot k_{f}}{n_v - 1}
\end{equation}

Following the method of deriving $p_1$, the probability of visiting the aggregate and core layers can be calculated by,
\begin{align}
\label{eq:p_agg_core}
&p_{ 2 }=\frac { (k/2-1)\cdot k\cdot k_{ f } }{ 2\cdot (n_{ v }-1) } \\ \nonumber \\
&p_{3} = \frac{n_v - (k/2)^2 \cdot k_{f}}{n_v - 1}
\end{align}

At the virtual switch, the SDN controller will only be consulted if the destination VNF is located in another physical server, and the packet does not match routing table of virtual switch in that server. Then, the probability that the packets will be sent to SDN controller for routing computation can be calculated by, 
\begin{equation}
\label{eq:p_sdn}
p_{c} = (1 - p_{0}) \cdot p_{m}
\end{equation}

After obtaining the probability that a packet will be processed at the different layers of switches and SDN controller. The following subsection derives the waiting time at each component of the routing path. According to \cite{Kleinrock75}, the waiting time for a M/M/1 queue is obtained by 
\begin{equation}
\label{eq:p_latency}
w(\mu, \lambda) = \frac{1}{\mu - \lambda}
\end{equation}
where $\mu$ is the service rate and $\lambda$ is the arrival rate for a M/M/1 queue.  In the following, we aim to calculate the arrive rate at the VNFs, SDN controller and different layers of switches. As the destination VNFs are evenly distributed over the VNFs, each destination VNF will receive an equal proportion of packets from other VNF. Hence the traffic arrives at the destination VNF at the rate of $\lambda_f$. Virtual switches realise the communications among VMs, so virtual switches can receive packets from three sources: 1) packets generated by VNFs on the server that the virtual switch locates; 2) the traffic generated by the VNFs in the other servers; and 3) the packets feed back from the SDN controller. Then the arrival rate at the virtual switch can be calculated by,
\begin{equation}
\label{eq:arr_srv}
\begin{split}
\lambda _{ 0 }={ \lambda  }_{ f }(1+\frac { n_v-k_{ v } }{ n_v-1 } +p_{ c })
\end{split}
\end{equation}

The arrival rate for the edge switches can be achieved similar to the virtual switch. It should be noticed that packets that are intended for destinations on the same server do not need to visit the edge switch. After a series of derivation, the arrival rate at the edge switch can be calculated by,
\begin{equation}
\label{eq:arr_edge}
\begin{split}
\lambda _{1}=\frac { { \lambda  }_{ f }\cdot k\cdot k_{ v } }{ 2(n_v-1) } (n_v-k_{ v }+\frac { (2n_v-k)\cdot k_{ v } }{ 2 } )
\end{split}
\end{equation}

According to the MCMR routing protocol in the datacenter network, the traffic will be balanced among aggregate switch in a pod. And the VNFs sharing the same virtual or edge switches will not reach the aggregation switches. Then arrival rate at the aggregate switch can be computed by,
\begin{equation}
\label{eq:arr_agg}
\begin{split}
\lambda _{ 2 }=\frac { { \lambda  }_{ f }\cdot k\cdot k_{ v } }{ 2({ n }_{ v }-1) } \left( 2{ n }_{ v }-\frac { k }{ 2 } \left( k_{ v }-\frac { k\cdot k_{ v } }{ 2 }  \right)  \right) 
\end{split}
\end{equation}

As all VNFs are connected by the core switches, the arrival rate at each core switch is the portion of traffic that their destination VNFs cannot be reached by edge or aggregation switches. Based on MCMR protocol, the traffic leaving the aggregation layer will be evenly split among different core switches. Therefore the arrival rate at the core switch is calculated by, 
\begin{equation}
\label{eq:arr_core}
\lambda _{ 3 }=\frac { { \lambda  }_{ f }\cdot p_{ o }\cdot { n }_{ v } }{ (k/2)^{ 2 } } 
\end{equation}

Finally, let us calculate the traffic rate for the SDN controller. It can be observed that the packets visiting the SDN controller do not change the arrival rate of higher level switches, e.g. edge or aggregation switches; and a portion of the traffic in the virtual switch will be sent to SDN controller for routing decision making. Given the number of the virtual switch ($n_v = k^2$), then the arrival rate at the SDN controller is computed by, 
\begin{equation}
\label{eq:arr_sdn}
\lambda _{ c }={ \lambda  }_{ f }\cdot p_{ c }\cdot { n }_{ v }
\end{equation}

By substituting the arrival rates (Eqs. \ref{eq:arr_edge} to \ref{eq:arr_core}) and service rates of each network component into M/M/1 latency equation, we can obtain the average waiting time at VNF, and different layers of switches. To calculate the latency caused by the round-trip between virtual switches and SDN controller, two latency components should be considered, the latency in the SDN controller and the latency in the virtual switch when the packet return back from the SDN controller. So, the additional latency caused by the SDN controller could be calculated by $w_{ d }={ w }_{ c }+w_{ v }$. Through taking the probabilities of the different paths and the mean waiting time into Eq. (\ref{eq:mean_latency}), we could obtain the end to end latency for the single VNF deployment scenario. 

\subsubsection{Multiple NFV Deployment Case} \label{multiple}
Although there are several researches investigating the performance of NFV, existing research only considered the case of a single NFV service deployment, paying little attention to the multiple NFV deployment. Given the fact that datacenter infrastructure is always used to simultaneously support multiple services, it is necessary to investigate the performance of SND and NFV enabled datacenter network with the different scale of service deployment. In this subsection, we will extend the simplified NFV deployment scenario into multiple NFV case. 

Let $N_s$ denote the number of NFV services deployed in datacenter and $K_i$ represent the length of $i$th service. Along the NFV chain, the packets will visit each VNF in sequence before arriving at the end VNF. So the VFN receives the traffic forwarded from the previous VNF, and produces and send the new packets to the next VNF. Therefore, each VNF except the last one would receive and generate packets simultaneously. From the perspective of the network transmission, the network infrastructure will receive the packets from $K_i-1$ VNFs for the $i$th service and the effective network traffic rate that $i$th service chain generates can be written as $\lambda_{i,f}^{e} = \lambda_{i,f} \cdot (K_i - 1)$, where $\lambda_{i,f}$ is the traffic rate of the $i$th service and the $\lambda_{i,f}^e$ is the effective traffic rate that the network infrastructure receives. In the abstracted analytical model, different network service would have different length of the service chain. In addition, the end-to-end latency a packet persisted in the network is dependent on both the type and service chain length of the network services. As NFV services are independent with each other, let $p_{i,s}$ denote the probability that a packet network device receives is from the $i$th service.
The effective network traffic the network infrastructure receives could be obtained by 
\begin{equation}
\label{eq:multip}
\lambda _{ f }^{ e }=\sum _{ i=1 }^{ { N }_{ s } }{p_{i,s} \cdot \lambda _{ i,f }\cdot (K_{ i }-1) }
\end{equation}

Similar to the single NFV deployment case, the end-to-end latency will be the probabilistic sum of the time spent taking each path. By inserting the effective traffic rate in Eq. (\ref{eq:multip}) in to Eqs. (\ref{eq:arr_srv}-\ref{eq:arr_sdn}), we could calculate the effective network traffic in each network layer. Given the service rates $\mu_v$, $\mu_e$, $\mu_a$, and $\mu_s$, the latency, $w_j$ could be obtained for different network layer. After calculating the probability that a packet visits a certain network layer, the end-to-end latency can be calculated by Eqs. (\ref{latency:path}) and (\ref{eq:mean_latency}). 
For convenience, pseudocode for the entire process is given in Algorithm \ref{alg:avg_latency_final}.

\begin{algorithm}

\caption{Calculation of Average Latency of SND and NFV-enabled MCC Datacenter Networks}
\label{alg:avg_latency_final}

\begin{algorithmic}[1]
%\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%\REQUIRE $\alpha$, $k$, $k_{vm}$, $\mu_{sw/vnf/sdn}$, $p_{miss\_route}$, $p(service_i)$ 
\STATE Calculate the effective network traffic: $\lambda_f^e$ \hfill(\textit{Eq. (\ref{eq:multip})})
\STATE Calculate the traffic rates: $\lambda_i$ \hfill(\textit{Eqs. (\ref{eq:p_srv}-\ref{sdn})})
\STATE Calculate the probability: $p_i$ \hfill(\textit{Eqs. (\ref{eq:arr_srv}-\ref{eq:arr_sdn})})
\STATE Calculate the waiting time: $w_j$ and $w_f$ \hfill(\textit{Eq. (\ref{eq:p_latency})})
\STATE Calculate the latency for the $i$th path: $L_i$ \hfill (\textit{Eq. (\ref{eq:latency:path})})
\STATE Calculate the latency for the end to end transmission: $L_t$ \hfill (\textit{Eq. (\ref{eq:mean_latency})})
\end{algorithmic}
\end{algorithm}